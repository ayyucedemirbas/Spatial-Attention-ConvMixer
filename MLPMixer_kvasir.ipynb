{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-ss4WhgUuGE",
        "outputId": "17b25e85-8b51-42c8-80fb-87f469370479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  /content/drive/MyDrive/kvasir_dataset.zip ."
      ],
      "metadata": {
        "id": "HqCYFqe-VFZj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq kvasir_dataset.zip"
      ],
      "metadata": {
        "id": "BBI9DGU9VHgN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf kvasir_dataset/train/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "O_8WlgQEVUJv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4GYYkjCVVVx",
        "outputId": "6bc7fae0-3383-4080-d3bd-9cdcd67f8142"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "sS0uT6qoVasW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.1\n",
        "image_size = 128  # We'll resize input images to this size.\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images.\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
        "embedding_dim = 256  # Number of hidden units.\n",
        "num_blocks = 6  # Number of blocks.\n",
        "\n",
        "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
        "print(f\"Patches per image: {num_patches}\")\n",
        "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQBdFsheVtji",
        "outputId": "d5cd8722-6e74-44ea-c25f-dbd8cc7720b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 128 X 128 = 16384\n",
            "Patch size: 8 X 8 = 64 \n",
            "Patches per image: 256\n",
            "Elements per patch (3 channels): 192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagePaths = \"kvasir_dataset/train/\"\n",
        "test_path = \"kvasir_dataset/test/\""
      ],
      "metadata": {
        "id": "tE6JmzgyZLsl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  imagePaths,\n",
        "  #color_mode='grayscale',\n",
        "  validation_split=0.15,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  #label_mode=\"categorical\",\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqky09h0Vllv",
        "outputId": "c4d45232-6eb1-4581-b3e7-04f28f1a0275"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15300 files belonging to 6 classes.\n",
            "Using 13005 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  imagePaths, \n",
        "  #color_mode='grayscale',\n",
        "  validation_split=0.15,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  #label_mode=\"categorical\",\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63OxiZ8IVnpm",
        "outputId": "f0c3a637-08c6-4367-a8cd-2de689774303"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15300 files belonging to 6 classes.\n",
            "Using 2295 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_path,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  #label_mode=\"categorical\",\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u7LuVvMVdLU",
        "outputId": "72a2d760-f9fd-4f81-86bc-940c6415786f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2700 files belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 6\n",
        "input_shape = (128, 128, 3)"
      ],
      "metadata": {
        "id": "QrPatN4zZaFC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(blocks, positional_encoding=False):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size, num_patches)(augmented)\n",
        "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
        "    x = layers.Dense(units=embedding_dim)(patches)\n",
        "    if positional_encoding:\n",
        "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "        position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=embedding_dim\n",
        "        )(positions)\n",
        "        x = x + position_embedding\n",
        "    # Process x using the module blocks.\n",
        "    x = blocks(x)\n",
        "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n",
        "    representation = layers.GlobalAveragePooling1D()(x)\n",
        "    # Apply dropout.\n",
        "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
        "    # Compute logits outputs.\n",
        "    logits = layers.Dense(num_classes)(representation)\n",
        "    # Create the Keras model.\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ],
      "metadata": {
        "id": "MWFMr3J_VqSN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    # Create Adam optimizer with weight decay.\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
        "    )\n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
        "        ],\n",
        "    )\n",
        "    # Create a learning rate scheduler callback.\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=5\n",
        "    )\n",
        "    # Create an early stopping callback.\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=100, restore_best_weights=True\n",
        "    )\n",
        "    # Fit the model.\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_ds,\n",
        "        callbacks=[reduce_lr],\n",
        "    )\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(test_ds)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    # Return history to plot learning curves.\n",
        "    return history"
      ],
      "metadata": {
        "id": "TtopTHQjV3G8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "EsAO4PS_ZgKB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation= Sequential([\n",
        "                               #layers.Rescaling(scale=1.0 / 255),\n",
        "                               layers.RandomBrightness(factor=0.2, value_range=(0, 255), seed=123)\n",
        "])"
      ],
      "metadata": {
        "id": "3Hw88kR8WgMy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, num_patches):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "n3roeozsW-XF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPMixerLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.mlp1 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=num_patches),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.mlp2 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=embedding_dim),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize(inputs)\n",
        "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
        "        x_channels = tf.linalg.matrix_transpose(x)\n",
        "        # Apply mlp1 on each channel independently.\n",
        "        mlp1_outputs = self.mlp1(x_channels)\n",
        "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
        "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
        "        # Add skip connection.\n",
        "        x = mlp1_outputs + inputs\n",
        "        # Apply layer normalization.\n",
        "        x_patches = self.normalize(x)\n",
        "        # Apply mlp2 on each patch independtenly.\n",
        "        mlp2_outputs = self.mlp2(x_patches)\n",
        "        # Add skip connection.\n",
        "        x = x + mlp2_outputs\n",
        "        return x"
      ],
      "metadata": {
        "id": "PGQHW8puXB2f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlpmixer_blocks = keras.Sequential(\n",
        "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.05\n",
        "mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n",
        "history = run_experiment(mlpmixer_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah6_ikhTXG_U",
        "outputId": "4cb716bd-8464-4543-9865-b4b915e67c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 259s 1s/step - loss: 466.9145 - acc: 0.4457 - top5-acc: 0.9559 - val_loss: 112.9930 - val_acc: 0.3425 - val_top5-acc: 0.9490 - lr: 0.0500\n",
            "Epoch 2/50\n",
            "204/204 [==============================] - 253s 1s/step - loss: 1438.0935 - acc: 0.4501 - top5-acc: 0.9562 - val_loss: 233.8462 - val_acc: 0.5769 - val_top5-acc: 0.9978 - lr: 0.0500\n",
            "Epoch 3/50\n",
            "204/204 [==============================] - 245s 1s/step - loss: 63.3798 - acc: 0.6120 - top5-acc: 0.9984 - val_loss: 35.1178 - val_acc: 0.5403 - val_top5-acc: 0.9917 - lr: 0.0500\n",
            "Epoch 4/50\n",
            "204/204 [==============================] - 243s 1s/step - loss: 18.3113 - acc: 0.6341 - top5-acc: 0.9992 - val_loss: 16.4720 - val_acc: 0.6209 - val_top5-acc: 0.9983 - lr: 0.0500\n",
            "Epoch 5/50\n",
            "204/204 [==============================] - 250s 1s/step - loss: 11.2172 - acc: 0.6365 - top5-acc: 0.9990 - val_loss: 21.6301 - val_acc: 0.5473 - val_top5-acc: 0.9978 - lr: 0.0500\n",
            "Epoch 6/50\n",
            "204/204 [==============================] - 247s 1s/step - loss: 6.4847 - acc: 0.6577 - top5-acc: 0.9996 - val_loss: 8.9823 - val_acc: 0.5730 - val_top5-acc: 0.9969 - lr: 0.0500\n",
            "Epoch 7/50\n",
            "204/204 [==============================] - 240s 1s/step - loss: 5.1002 - acc: 0.6527 - top5-acc: 0.9989 - val_loss: 12.7979 - val_acc: 0.5595 - val_top5-acc: 0.9991 - lr: 0.0500\n",
            "Epoch 8/50\n",
            "204/204 [==============================] - 240s 1s/step - loss: 4.3956 - acc: 0.6528 - top5-acc: 0.9994 - val_loss: 9.0523 - val_acc: 0.5930 - val_top5-acc: 0.9987 - lr: 0.0500\n",
            "Epoch 9/50\n",
            "204/204 [==============================] - 247s 1s/step - loss: 25898.4629 - acc: 0.4795 - top5-acc: 0.9616 - val_loss: 5673.2554 - val_acc: 0.4379 - val_top5-acc: 0.9926 - lr: 0.0500\n",
            "Epoch 10/50\n",
            "204/204 [==============================] - 243s 1s/step - loss: 1241.2030 - acc: 0.5809 - top5-acc: 0.9916 - val_loss: 667.3978 - val_acc: 0.5612 - val_top5-acc: 0.9935 - lr: 0.0500\n",
            "Epoch 11/50\n",
            "204/204 [==============================] - 247s 1s/step - loss: 314.1987 - acc: 0.6283 - top5-acc: 0.9968 - val_loss: 283.1153 - val_acc: 0.6044 - val_top5-acc: 0.9978 - lr: 0.0500\n",
            "Epoch 12/50\n",
            "204/204 [==============================] - 239s 1s/step - loss: 151.1454 - acc: 0.6610 - top5-acc: 0.9987 - val_loss: 155.2950 - val_acc: 0.6462 - val_top5-acc: 0.9991 - lr: 0.0250\n",
            "Epoch 13/50\n",
            "204/204 [==============================] - 242s 1s/step - loss: 109.8226 - acc: 0.6628 - top5-acc: 0.9990 - val_loss: 69.8931 - val_acc: 0.6932 - val_top5-acc: 0.9996 - lr: 0.0250\n",
            "Epoch 14/50\n",
            "204/204 [==============================] - 249s 1s/step - loss: 87.3561 - acc: 0.6638 - top5-acc: 0.9988 - val_loss: 67.4410 - val_acc: 0.6797 - val_top5-acc: 0.9991 - lr: 0.0250\n",
            "Epoch 15/50\n",
            "204/204 [==============================] - 246s 1s/step - loss: 70.7957 - acc: 0.6655 - top5-acc: 0.9988 - val_loss: 48.4770 - val_acc: 0.7024 - val_top5-acc: 0.9987 - lr: 0.0250\n",
            "Epoch 16/50\n",
            "204/204 [==============================] - 248s 1s/step - loss: 55.3684 - acc: 0.6720 - top5-acc: 0.9990 - val_loss: 44.3429 - val_acc: 0.7150 - val_top5-acc: 0.9983 - lr: 0.0250\n",
            "43/43 [==============================] - 39s 716ms/step - loss: 9.3560 - acc: 0.5715 - top5-acc: 0.9941\n",
            "Test accuracy: 57.15%\n",
            "Test top 5 accuracy: 99.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlpmixer_blocks = keras.Sequential(\n",
        "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
        ")\n",
        "learning_rate = 0.05\n",
        "mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n",
        "history = run_experiment(mlpmixer_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU4vs61uvPJa",
        "outputId": "0e5aec77-45b6-462b-9c6c-9d8115891c2e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 243s 1s/step - loss: 753.8687 - acc: 0.4190 - top5-acc: 0.9559 - val_loss: 77.0919 - val_acc: 0.2871 - val_top5-acc: 0.9569 - lr: 0.0500\n",
            "Epoch 2/50\n",
            "204/204 [==============================] - 226s 1s/step - loss: 135.5065 - acc: 0.5020 - top5-acc: 0.9762 - val_loss: 4064.2944 - val_acc: 0.2362 - val_top5-acc: 0.8370 - lr: 0.0500\n",
            "Epoch 3/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 534.3361 - acc: 0.5256 - top5-acc: 0.9830 - val_loss: 10.6375 - val_acc: 0.6993 - val_top5-acc: 0.9996 - lr: 0.0500\n",
            "Epoch 4/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 11.6115 - acc: 0.6336 - top5-acc: 0.9986 - val_loss: 7.3482 - val_acc: 0.6501 - val_top5-acc: 0.9969 - lr: 0.0500\n",
            "Epoch 5/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 7.4720 - acc: 0.6281 - top5-acc: 0.9978 - val_loss: 4.5964 - val_acc: 0.6754 - val_top5-acc: 1.0000 - lr: 0.0500\n",
            "Epoch 6/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 5.1430 - acc: 0.6361 - top5-acc: 0.9982 - val_loss: 4.1938 - val_acc: 0.6566 - val_top5-acc: 1.0000 - lr: 0.0500\n",
            "Epoch 7/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.2136 - acc: 0.6405 - top5-acc: 0.9987 - val_loss: 2.9609 - val_acc: 0.6318 - val_top5-acc: 0.9996 - lr: 0.0500\n",
            "Epoch 8/50\n",
            "204/204 [==============================] - 223s 1s/step - loss: 25650.3945 - acc: 0.5287 - top5-acc: 0.9666 - val_loss: 77515.0000 - val_acc: 0.2231 - val_top5-acc: 0.8275 - lr: 0.0500\n",
            "Epoch 9/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 18802.0137 - acc: 0.4643 - top5-acc: 0.9628 - val_loss: 478.8509 - val_acc: 0.5643 - val_top5-acc: 0.9961 - lr: 0.0500\n",
            "Epoch 10/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 392.4688 - acc: 0.5999 - top5-acc: 0.9931 - val_loss: 236.1706 - val_acc: 0.6575 - val_top5-acc: 0.9987 - lr: 0.0500\n",
            "Epoch 11/50\n",
            "204/204 [==============================] - 223s 1s/step - loss: 217.9810 - acc: 0.6196 - top5-acc: 0.9964 - val_loss: 179.9187 - val_acc: 0.6340 - val_top5-acc: 0.9996 - lr: 0.0500\n",
            "Epoch 12/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 134.0255 - acc: 0.6391 - top5-acc: 0.9977 - val_loss: 111.8600 - val_acc: 0.6466 - val_top5-acc: 1.0000 - lr: 0.0500\n",
            "Epoch 13/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 82.4330 - acc: 0.6515 - top5-acc: 0.9987 - val_loss: 67.4531 - val_acc: 0.6906 - val_top5-acc: 1.0000 - lr: 0.0250\n",
            "Epoch 14/50\n",
            "204/204 [==============================] - 223s 1s/step - loss: 64.3740 - acc: 0.6581 - top5-acc: 0.9988 - val_loss: 55.7289 - val_acc: 0.6824 - val_top5-acc: 0.9996 - lr: 0.0250\n",
            "Epoch 15/50\n",
            "204/204 [==============================] - 223s 1s/step - loss: 53.6597 - acc: 0.6615 - top5-acc: 0.9988 - val_loss: 51.3999 - val_acc: 0.6815 - val_top5-acc: 1.0000 - lr: 0.0250\n",
            "Epoch 16/50\n",
            "204/204 [==============================] - 226s 1s/step - loss: 45.5084 - acc: 0.6683 - top5-acc: 0.9986 - val_loss: 34.8148 - val_acc: 0.6745 - val_top5-acc: 0.9996 - lr: 0.0250\n",
            "Epoch 17/50\n",
            "204/204 [==============================] - 223s 1s/step - loss: 40.9677 - acc: 0.6657 - top5-acc: 0.9984 - val_loss: 29.7709 - val_acc: 0.6985 - val_top5-acc: 0.9996 - lr: 0.0250\n",
            "Epoch 18/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 30.1802 - acc: 0.6684 - top5-acc: 0.9987 - val_loss: 27.3444 - val_acc: 0.6941 - val_top5-acc: 0.9996 - lr: 0.0125\n",
            "Epoch 19/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 25.2566 - acc: 0.6719 - top5-acc: 0.9994 - val_loss: 17.2515 - val_acc: 0.7233 - val_top5-acc: 0.9996 - lr: 0.0125\n",
            "Epoch 20/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 24.0534 - acc: 0.6663 - top5-acc: 0.9992 - val_loss: 28.9974 - val_acc: 0.6667 - val_top5-acc: 1.0000 - lr: 0.0125\n",
            "Epoch 21/50\n",
            "204/204 [==============================] - 225s 1s/step - loss: 21.1585 - acc: 0.6700 - top5-acc: 0.9990 - val_loss: 21.7688 - val_acc: 0.6719 - val_top5-acc: 0.9996 - lr: 0.0125\n",
            "Epoch 22/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 20.1463 - acc: 0.6687 - top5-acc: 0.9991 - val_loss: 12.7458 - val_acc: 0.7120 - val_top5-acc: 1.0000 - lr: 0.0125\n",
            "Epoch 23/50\n",
            "204/204 [==============================] - 223s 1s/step - loss: 14.4224 - acc: 0.6827 - top5-acc: 0.9996 - val_loss: 14.7314 - val_acc: 0.6815 - val_top5-acc: 1.0000 - lr: 0.0063\n",
            "Epoch 24/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 13.4047 - acc: 0.6794 - top5-acc: 0.9993 - val_loss: 12.7526 - val_acc: 0.7089 - val_top5-acc: 1.0000 - lr: 0.0063\n",
            "Epoch 25/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 12.6523 - acc: 0.6760 - top5-acc: 0.9993 - val_loss: 13.0850 - val_acc: 0.6850 - val_top5-acc: 0.9996 - lr: 0.0063\n",
            "Epoch 26/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 10.7948 - acc: 0.6804 - top5-acc: 0.9992 - val_loss: 9.0581 - val_acc: 0.7076 - val_top5-acc: 0.9996 - lr: 0.0063\n",
            "Epoch 27/50\n",
            "204/204 [==============================] - 226s 1s/step - loss: 10.2958 - acc: 0.6787 - top5-acc: 0.9990 - val_loss: 12.1252 - val_acc: 0.6902 - val_top5-acc: 1.0000 - lr: 0.0063\n",
            "Epoch 28/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 8.4684 - acc: 0.6839 - top5-acc: 0.9995 - val_loss: 7.3782 - val_acc: 0.7303 - val_top5-acc: 1.0000 - lr: 0.0031\n",
            "Epoch 29/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 8.0868 - acc: 0.6810 - top5-acc: 0.9995 - val_loss: 6.4203 - val_acc: 0.7098 - val_top5-acc: 1.0000 - lr: 0.0031\n",
            "Epoch 30/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 7.0596 - acc: 0.6793 - top5-acc: 0.9994 - val_loss: 5.5304 - val_acc: 0.7342 - val_top5-acc: 0.9996 - lr: 0.0031\n",
            "Epoch 31/50\n",
            "204/204 [==============================] - 225s 1s/step - loss: 7.2055 - acc: 0.6770 - top5-acc: 0.9994 - val_loss: 6.7812 - val_acc: 0.7015 - val_top5-acc: 0.9991 - lr: 0.0031\n",
            "Epoch 32/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 6.5510 - acc: 0.6800 - top5-acc: 0.9998 - val_loss: 7.5711 - val_acc: 0.6732 - val_top5-acc: 1.0000 - lr: 0.0031\n",
            "Epoch 33/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 5.3723 - acc: 0.6908 - top5-acc: 0.9995 - val_loss: 4.0567 - val_acc: 0.7224 - val_top5-acc: 0.9991 - lr: 0.0016\n",
            "Epoch 34/50\n",
            "204/204 [==============================] - 225s 1s/step - loss: 5.2803 - acc: 0.6825 - top5-acc: 0.9991 - val_loss: 3.9512 - val_acc: 0.7190 - val_top5-acc: 0.9996 - lr: 0.0016\n",
            "Epoch 35/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 4.9246 - acc: 0.6874 - top5-acc: 0.9995 - val_loss: 3.2178 - val_acc: 0.7246 - val_top5-acc: 0.9991 - lr: 0.0016\n",
            "Epoch 36/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 4.8857 - acc: 0.6810 - top5-acc: 0.9992 - val_loss: 3.3553 - val_acc: 0.7190 - val_top5-acc: 0.9996 - lr: 0.0016\n",
            "Epoch 37/50\n",
            "204/204 [==============================] - 226s 1s/step - loss: 4.4048 - acc: 0.6779 - top5-acc: 0.9991 - val_loss: 2.9865 - val_acc: 0.7342 - val_top5-acc: 0.9991 - lr: 0.0016\n",
            "Epoch 38/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.9167 - acc: 0.6854 - top5-acc: 0.9992 - val_loss: 2.7476 - val_acc: 0.7272 - val_top5-acc: 1.0000 - lr: 7.8125e-04\n",
            "Epoch 39/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.8283 - acc: 0.6811 - top5-acc: 0.9994 - val_loss: 2.9337 - val_acc: 0.7185 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 40/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.9545 - acc: 0.6804 - top5-acc: 0.9992 - val_loss: 2.5983 - val_acc: 0.7216 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 41/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.6293 - acc: 0.6729 - top5-acc: 0.9992 - val_loss: 3.0032 - val_acc: 0.7185 - val_top5-acc: 0.9991 - lr: 7.8125e-04\n",
            "Epoch 42/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.6077 - acc: 0.6754 - top5-acc: 0.9992 - val_loss: 2.2901 - val_acc: 0.7246 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 43/50\n",
            "204/204 [==============================] - 226s 1s/step - loss: 3.4292 - acc: 0.6740 - top5-acc: 0.9988 - val_loss: 2.2375 - val_acc: 0.7150 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 44/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 3.1305 - acc: 0.6728 - top5-acc: 0.9991 - val_loss: 2.1044 - val_acc: 0.6898 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 45/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 2.9847 - acc: 0.6733 - top5-acc: 0.9989 - val_loss: 2.1118 - val_acc: 0.7246 - val_top5-acc: 1.0000 - lr: 7.8125e-04\n",
            "Epoch 46/50\n",
            "204/204 [==============================] - 225s 1s/step - loss: 2.7362 - acc: 0.6810 - top5-acc: 0.9991 - val_loss: 1.7987 - val_acc: 0.7316 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 47/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 2.3975 - acc: 0.6816 - top5-acc: 0.9992 - val_loss: 1.4869 - val_acc: 0.7346 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 48/50\n",
            "204/204 [==============================] - 224s 1s/step - loss: 2.5541 - acc: 0.6724 - top5-acc: 0.9991 - val_loss: 1.5493 - val_acc: 0.7229 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 49/50\n",
            "204/204 [==============================] - 241s 1s/step - loss: 2.4518 - acc: 0.6719 - top5-acc: 0.9990 - val_loss: 1.8825 - val_acc: 0.6980 - val_top5-acc: 0.9996 - lr: 7.8125e-04\n",
            "Epoch 50/50\n",
            "204/204 [==============================] - 242s 1s/step - loss: 2.2996 - acc: 0.6713 - top5-acc: 0.9994 - val_loss: 2.2658 - val_acc: 0.6545 - val_top5-acc: 1.0000 - lr: 7.8125e-04\n",
            "43/43 [==============================] - 35s 658ms/step - loss: 2.8807 - acc: 0.6304 - top5-acc: 0.9996\n",
            "Test accuracy: 63.04%\n",
            "Test top 5 accuracy: 99.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlpmixer_classifier.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju2J201-suv0",
        "outputId": "9a8e3f00-d716-4a5c-b84a-b7eb678a4c2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43/43 [==============================] - 30s 569ms/step - loss: 2.8807 - acc: 0.6304 - top5-acc: 0.9996\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.8806607723236084, 0.6303703784942627, 0.9996296167373657]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_cfn5HKBsx5W"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "for x, y in test_ds:\n",
        "  Y_pred=mlpmixer_classifier.predict(x)\n",
        "  y_prediction = np.argmax(Y_pred, axis=1)\n",
        "  predictions = np.concatenate([predictions, y_prediction])\n",
        "  labels = np.concatenate([labels, y.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3pakf-As7K5",
        "outputId": "e3bcaee6-421d-459d-85f0-a291b633f49c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 43ms/step\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 0s 39ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 46ms/step\n",
            "2/2 [==============================] - 0s 42ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 42ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 39ms/step\n",
            "2/2 [==============================] - 0s 43ms/step\n",
            "2/2 [==============================] - 0s 39ms/step\n",
            "2/2 [==============================] - 0s 40ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 42ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 0s 35ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 30ms/step\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "2/2 [==============================] - 0s 28ms/step\n",
            "2/2 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true=labels, y_pred=predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "griZc1dns_ZH",
        "outputId": "c1e94a01-8401-4c2d-88f1-14a5736e4d80"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[ 93 355   1   0   1   0]\n",
            " [ 41 406   0   2   1   0]\n",
            " [  0   1 371  77   1   0]\n",
            " [  8   5  31 397   8   1]\n",
            " [ 16  26   8  59 320  21]\n",
            " [  7   6   3  38 281 115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=['dyed-lifted-polyps','dyed-resection-margins', 'esophagitis','normal','polyps', 'ulcerative-colitis']\n",
        "     \n",
        "print('Classification Report')\n",
        "target_names = classes\n",
        "print(classification_report(y_true=labels, y_pred=predictions, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvNoB4FztC1O",
        "outputId": "e08132fd-047f-4aa2-c77c-55b7d68ac7f3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "    dyed-lifted-polyps       0.56      0.21      0.30       450\n",
            "dyed-resection-margins       0.51      0.90      0.65       450\n",
            "           esophagitis       0.90      0.82      0.86       450\n",
            "                normal       0.69      0.88      0.78       450\n",
            "                polyps       0.52      0.71      0.60       450\n",
            "    ulcerative-colitis       0.84      0.26      0.39       450\n",
            "\n",
            "              accuracy                           0.63      2700\n",
            "             macro avg       0.67      0.63      0.60      2700\n",
            "          weighted avg       0.67      0.63      0.60      2700\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlpmixer_classifier.save(\"mlpmixer_classifier_kvasir\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8bFF4ENtQqv",
        "outputId": "e0fa2361-9324-4d5b-8b1c-74cde4948e7d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:absl:Found untraced functions such as layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, layer_normalization_1_layer_call_fn, layer_normalization_1_layer_call_and_return_conditional_losses, layer_normalization_2_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r mlpmixer_classifier_kvasir.zip mlpmixer_classifier_kvasir/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7zWV3A_tYX8",
        "outputId": "6e978ead-2203-49a0-c126-242ec64ceda7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: mlpmixer_classifier_kvasir/ (stored 0%)\n",
            "  adding: mlpmixer_classifier_kvasir/saved_model.pb (deflated 92%)\n",
            "  adding: mlpmixer_classifier_kvasir/keras_metadata.pb (deflated 95%)\n",
            "  adding: mlpmixer_classifier_kvasir/variables/ (stored 0%)\n",
            "  adding: mlpmixer_classifier_kvasir/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: mlpmixer_classifier_kvasir/variables/variables.index (deflated 79%)\n",
            "  adding: mlpmixer_classifier_kvasir/assets/ (stored 0%)\n"
          ]
        }
      ]
    }
  ]
}